{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-13143efe4a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-13143efe4a77>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(_X, _istate, _weights, _biases)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0m_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (?, n_hidden)+scalar(n_hidden,)=(?,n_hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Define a lstm cell with tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mlstm_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforget_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Split data because rnn cell needs a list of inputs for the RNN inner loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# n_steps splits each of which contains (?, n_hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "#!/bin/env python\n",
    "\n",
    "'''\n",
    "reference : https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/recurrent_network.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.compat.v1.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.compat.v1.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.compat.v1.constant(0.1, shape=shape)\n",
    "    return tf.compat.v1.Variable(initial)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 64\n",
    "display_step = 10\n",
    "\n",
    "n_input = 28   # row length of 28 x 28 image\n",
    "n_steps = 28   # 28 time steps\n",
    "n_hidden = 128 # hidden state size = lstm_size\n",
    "n_classes = 10 # output classes\n",
    "\n",
    "x = tf.compat.v1.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y_ = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# LSTM layer\n",
    "\n",
    "# 2 x n_hidden = state_size = (hidden state + cell state)\n",
    "istate = tf.compat.v1.placeholder(\"float\", [None, 2*n_hidden])\n",
    "weights = {\n",
    "    'hidden' : weight_variable([n_input, n_hidden]),\n",
    "    'out' : weight_variable([n_hidden, n_classes])\n",
    "}\n",
    "biases = {\n",
    "    'hidden' : bias_variable([n_hidden]),\n",
    "    'out': bias_variable([n_classes])\n",
    "}\n",
    "\n",
    "def RNN(_X, _istate, _weights, _biases):\n",
    "    # input _X shape: (batch_size, n_steps, n_input), Tensor(\"Placeholder:0\", shape=(?, 28, 28), dtype=float32)\n",
    "    # switch n_steps and batch_size, (n_steps, batch_size, n_input), Tensor(\"transpose:0\", shape=(28, ?, 28), dtype=float32)\n",
    "    _X = tf.compat.v1.transpose(_X, [1, 0, 2])\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    # (n_steps*batch_size, n_input) = (?, n_input), Tensor(\"Reshape:0\", shape=(?, 28), dtype=float32)\n",
    "    _X = tf.compat.v1.reshape(_X, [-1, n_input])\n",
    "\n",
    "    # Linear activation\n",
    "    _X = tf.compat.v1.matmul(_X, _weights['hidden']) + _biases['hidden'] # (?, n_hidden)+scalar(n_hidden,)=(?,n_hidden)\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.compat.v1.contrib.rnn.LSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=False)\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    # n_steps splits each of which contains (?, n_hidden)\n",
    "    # ex) [<tf.compat.v1.Tensor 'split:0' shape=(?, 128) dtype=float32>, ... , <tf.compat.v1.Tensor 'split:27' shape=(?, 128) dtype=float32>]\n",
    "    _X = tf.compat.v1.split(_X, n_steps, 0)\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(cell=lstm_cell, inputs=_X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.compat.v1.matmul(outputs[-1], _weights['out']) + _biases['out']\n",
    "\n",
    "y = RNN(x, istate, weights, biases)\n",
    "\n",
    "# training\n",
    "cost = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_)) # Softmax loss\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(y,1), tf.compat.v1.argmax(y_,1))\n",
    "accuracy = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, tf.compat.v1.float32))\n",
    "NUM_THREADS = 5\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=NUM_THREADS,inter_op_parallelism_threads=NUM_THREADS,log_device_placement=False))\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "step = 1\n",
    "while step * batch_size < training_iters :\n",
    "    # [batch_size, 28 x 28], [batch_size, 10]\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    # [batch_size, 28 x 28] -> [batch_size, n_steps, n_input]\n",
    "    batch_xs = batch_xs.reshape((batch_size, n_steps, n_input))\n",
    "    # [batch_size, 2*128] \n",
    "    c_istate = np.zeros((batch_size, 2*n_hidden))\n",
    "    sess.run(optimizer, feed_dict={x: batch_xs, y_: batch_ys, istate: c_istate})\n",
    "    if step % display_step == 0 :\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys, istate: c_istate})\n",
    "        loss = sess.run(cost, feed_dict={x: batch_xs, y_: batch_ys, istate: c_istate})\n",
    "        print(\"step : \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "    step += 1\n",
    "\n",
    "# inference\n",
    "test_len = 256\n",
    "test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "test_label = mnist.test.labels[:test_len]\n",
    "print(\"test accuracy : \", sess.run(accuracy, feed_dict={x: test_data, y_: test_label, istate: np.zeros((test_len, 2*n_hidden))}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
