{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MLP with no hidden layer and 10 output neurons with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Mrityunjay kumar #\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import input_data\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0129 12:07:23.187964 4461352384 deprecation.py:323] From <ipython-input-2-46e7270fb8aa>:7: read_data_sets (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "W0129 12:07:23.189398 4461352384 deprecation.py:323] From /Users/mrityunjay/Desktop/Mrityunjay_Kumar/Tensor_NN/input_data.py:297: _maybe_download (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0129 12:07:23.190642 4461352384 deprecation.py:323] From /Users/mrityunjay/Desktop/Mrityunjay_Kumar/Tensor_NN/input_data.py:299: _extract_images (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0129 12:07:23.558176 4461352384 deprecation.py:323] From /Users/mrityunjay/Desktop/Mrityunjay_Kumar/Tensor_NN/input_data.py:304: _extract_labels (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0129 12:07:23.561424 4461352384 deprecation.py:323] From /Users/mrityunjay/Desktop/Mrityunjay_Kumar/Tensor_NN/input_data.py:112: _dense_to_one_hot (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0129 12:07:23.629658 4461352384 deprecation.py:323] From /Users/mrityunjay/Desktop/Mrityunjay_Kumar/Tensor_NN/input_data.py:328: _DataSet.__init__ (from input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you could also get data from the web, this way\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "dir=\"MNIST/\"\n",
    "# Import data\n",
    "mnist = input_data.read_data_sets(dir, one_hot=True)\n",
    "mnist.train.images.shape\n",
    "mnist.train.labels.shape\n",
    "mnist.test.images.shape\n",
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]\n",
    "mnist.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def gen_image(arr):\n",
    "    two_d = (np.reshape(arr, (28, 28)) * 255).astype(np.uint8)\n",
    "    plt.imshow(two_d)\n",
    "    return plt\n",
    "\n",
    "#mnist.test.images[0]\n",
    "gen_image(mnist.test.images[0]).show()\n",
    "gen_image(mnist.test.images[1]).show()\n",
    "print(mnist.test.labels[0], mnist.test.labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "x = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, 784])\n",
    "W = tf.compat.v1.Variable(tf.compat.v1.zeros([784, 10]))\n",
    "b = tf.compat.v1.Variable(tf.compat.v1.zeros([10]))\n",
    "y = tf.compat.v1.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0129 12:09:21.255573 4461352384 deprecation.py:323] From <ipython-input-7-b46b91642a54>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss and optimizer\n",
    "y_ = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, 10])\n",
    "cross_entropy = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.compat.v1.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 505 ms, total: 2.14 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, {x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9182\n",
      "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([-0.3733227 ,  0.33811742,  0.12000671, -0.26702067, -0.02273169,\n",
      "        1.3163751 , -0.07397537,  0.6300826 , -1.4320596 , -0.23547181],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "y.shape\n",
    "y_.shape\n",
    "# Test trained model\n",
    "correct_prediction = tf.compat.v1.equal(tf.argmax(y, 1), tf.compat.v1.argmax(y_, 1))\n",
    "accuracy = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, tf.compat.v1.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                  y_: mnist.test.labels}))\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with multiple hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import input_data\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "\n",
    "dir=\"MNIST/\"\n",
    "NUM_CLASSES = 10\n",
    "# The MNIST images are always 28x28 pixels.\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "batch_size=100\n",
    "hidden1=128\n",
    "hidden2=32\n",
    "learning_rate=0.01\n",
    "log_dir=\"logs/\"\n",
    "max_steps=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate placeholder variables to represent the input tensors.\n",
    "def placeholder_inputs(batch_size):\n",
    "  images_placeholder = tf.compat.v1.placeholder(tf.compat.v1.float32, shape=(batch_size, IMAGE_PIXELS))\n",
    "  labels_placeholder = tf.compat.v1.placeholder(tf.compat.v1.int32, shape=(batch_size))\n",
    "  return images_placeholder, labels_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fills the feed_dict for training the given step with the next \"batch size\" examples\n",
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "  images_feed, labels_feed = data_set.next_batch(batch_size)\n",
    "  feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "  }\n",
    "  return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs one evaluation against the full epoch of data.\n",
    "def do_eval(sess,eval_correct,images_placeholder,labels_placeholder,data_set):\n",
    "  true_count = 0  # Counts the number of correct predictions.\n",
    "  steps_per_epoch = data_set.num_examples // batch_size\n",
    "  num_examples = steps_per_epoch * batch_size\n",
    "  for step in range(steps_per_epoch):\n",
    "    feed_dict = fill_feed_dict(data_set,images_placeholder,labels_placeholder)\n",
    "    true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "  precision = float(true_count) / num_examples\n",
    "  print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "        (num_examples, true_count, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the MNIST model\n",
    "def inference(images, hidden1_units, hidden2_units):\n",
    "  # Hidden 1\n",
    "  with tf.compat.v1.name_scope('hidden1'):\n",
    "    weights = tf.compat.v1.Variable(tf.compat.v1.truncated_normal([IMAGE_PIXELS, hidden1_units],\n",
    "                            stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))), name='weights')\n",
    "    biases = tf.compat.v1.Variable(tf.zeros([hidden1_units]), name='biases')\n",
    "    hidden1 = tf.compat.v1.nn.relu(tf.matmul(images, weights) + biases)\n",
    "  # Hidden 2\n",
    "  with tf.compat.v1.name_scope('hidden2'):\n",
    "    weights = tf.compat.v1.Variable(tf.compat.v1.truncated_normal([hidden1_units, hidden2_units],\n",
    "                            stddev=1.0 / math.sqrt(float(hidden1_units))), name='weights')\n",
    "    biases = tf.compat.v1.Variable(tf.compat.v1.zeros([hidden2_units]), name='biases')\n",
    "    hidden2 = tf.compat.v1.nn.relu(tf.compat.v1.matmul(hidden1, weights) + biases)\n",
    "  # Linear\n",
    "  with tf.compat.v1.name_scope('softmax_linear'):\n",
    "    weights = tf.compat.v1.Variable(tf.compat.v1.truncated_normal([hidden2_units, NUM_CLASSES],\n",
    "                            stddev=1.0 / math.sqrt(float(hidden2_units))), name='weights')\n",
    "    biases = tf.compat.v1.Variable(tf.zeros([NUM_CLASSES]), name='biases')\n",
    "    logits = tf.compat.v1.matmul(hidden2, weights) + biases\n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the loss from the logits and the labels.\n",
    "def lossFn(logits, labels):\n",
    "  labels = tf.compat.v1.to_int64(labels)\n",
    "  cross_entropy = tf.compat.v1.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits, name='xentropy')\n",
    "  return tf.compat.v1.reduce_mean(cross_entropy, name='xentropy_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(loss, learning_rate):\n",
    "  # Add a scalar summary for the snapshot loss.\n",
    "  tf.compat.v1.summary.scalar('loss', loss)\n",
    "  optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate)\n",
    "  # Create a variable to track the global step.\n",
    "  global_step = tf.compat.v1.Variable(0, name='global_step', trainable=False)\n",
    "  train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "  return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the quality of the logits at predicting the label.\n",
    "def evaluation(logits, labels):\n",
    "  # For a classifier model, we can use the in_top_k Op.\n",
    "  # It returns a bool tensor with shape [batch_size] that is true for\n",
    "  # the examples where the label is in the top k (here k=1)\n",
    "  # of all logits for that example.\n",
    "  correct = tf.compat.v1.nn.in_top_k(logits, labels, 1)\n",
    "  # Return the number of true entries.\n",
    "  return tf.compat.v1.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train MNIST for a number of steps\n",
    "def run_training():\n",
    "  # Get the sets of images and labels for training, validation, and\n",
    "  # test on MNIST.\n",
    "  data_sets = input_data.read_data_sets(dir)\n",
    "  with tf.compat.v1.Graph().as_default():\n",
    "    images_placeholder, labels_placeholder = placeholder_inputs(batch_size)\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = inference(images_placeholder, hidden1, hidden2)\n",
    "    loss = lossFn(logits, labels_placeholder)\n",
    "    train_op = training(loss, learning_rate)\n",
    "    eval_correct = evaluation(logits, labels_placeholder)\n",
    "    \n",
    "    summary = tf.compat.v1.summary.merge_all()\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "\n",
    "    init = tf.compat.v1.global_variables_initializer()\n",
    "    sess = tf.compat.v1.Session()\n",
    "    sess.run(init)\n",
    "    summary_writer = tf.compat.v1.summary.FileWriter(log_dir, sess.graph)\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      start_time = time.time()\n",
    "      feed_dict = fill_feed_dict(data_sets.train, images_placeholder, labels_placeholder)\n",
    "      #The return values are the activations\n",
    "      # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "      # inspect the values of your Ops or variables, you may include them\n",
    "      # in the list passed to sess.run() and the value tensors will be\n",
    "      # returned in the tuple from the call.\n",
    "      _, loss_value = sess.run([train_op, loss],feed_dict=feed_dict)\n",
    "      duration = time.time() - start_time\n",
    "\n",
    "      # Write the summaries and print an overview fairly often.\n",
    "      if step % 100 == 0:\n",
    "        print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "        summary_str = sess.run(summary, feed_dict=feed_dict)\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "        summary_writer.flush()\n",
    "\n",
    "      # Save a checkpoint and evaluate the model periodically.\n",
    "      if (step + 1) % 1000 == 0 or (step + 1) == max_steps:\n",
    "        checkpoint_file = os.path.join(log_dir, 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_file, global_step=step)\n",
    "        # Evaluate against the training set.\n",
    "        print('Training Data Eval:')\n",
    "        do_eval(sess,eval_correct,images_placeholder,labels_placeholder,data_sets.train)\n",
    "        # Evaluate against the validation set.\n",
    "        print('Validation Data Eval:')\n",
    "        do_eval(sess,eval_correct,images_placeholder,labels_placeholder,data_sets.validation)\n",
    "        # Evaluate against the test set.\n",
    "        print('Test Data Eval:')\n",
    "        do_eval(sess,eval_correct,images_placeholder,labels_placeholder,data_sets.test)\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0129 12:13:37.874177 4461352384 deprecation.py:323] From <ipython-input-18-bf408975fd07>:3: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 2.31 (0.347 sec)\n",
      "Step 100: loss = 2.15 (0.001 sec)\n",
      "Step 200: loss = 1.93 (0.001 sec)\n",
      "Step 300: loss = 1.52 (0.002 sec)\n",
      "Step 400: loss = 1.22 (0.001 sec)\n",
      "Step 500: loss = 1.09 (0.001 sec)\n",
      "Step 600: loss = 0.75 (0.001 sec)\n",
      "Step 700: loss = 0.62 (0.002 sec)\n",
      "Step 800: loss = 0.52 (0.002 sec)\n",
      "Step 900: loss = 0.55 (0.001 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 47610  Precision @ 1: 0.8656\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4364  Precision @ 1: 0.8728\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 8739  Precision @ 1: 0.8739\n",
      "Step 1000: loss = 0.45 (0.018 sec)\n",
      "Step 1100: loss = 0.44 (0.157 sec)\n",
      "Step 1200: loss = 0.41 (0.002 sec)\n",
      "Step 1300: loss = 0.54 (0.001 sec)\n",
      "Step 1400: loss = 0.33 (0.001 sec)\n",
      "Step 1500: loss = 0.41 (0.002 sec)\n",
      "Step 1600: loss = 0.42 (0.005 sec)\n",
      "Step 1700: loss = 0.55 (0.001 sec)\n",
      "Step 1800: loss = 0.43 (0.001 sec)\n",
      "Step 1900: loss = 0.50 (0.002 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 49335  Precision @ 1: 0.8970\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4514  Precision @ 1: 0.9028\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 9022  Precision @ 1: 0.9022\n",
      "Step 2000: loss = 0.43 (0.020 sec)\n",
      "Step 2100: loss = 0.28 (0.001 sec)\n",
      "Step 2200: loss = 0.30 (0.172 sec)\n",
      "Step 2300: loss = 0.36 (0.002 sec)\n",
      "Step 2400: loss = 0.40 (0.002 sec)\n",
      "Step 2500: loss = 0.28 (0.001 sec)\n",
      "Step 2600: loss = 0.27 (0.001 sec)\n",
      "Step 2700: loss = 0.34 (0.001 sec)\n",
      "Step 2800: loss = 0.27 (0.001 sec)\n",
      "Step 2900: loss = 0.33 (0.001 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 50057  Precision @ 1: 0.9101\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4581  Precision @ 1: 0.9162\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 9122  Precision @ 1: 0.9122\n",
      "Step 3000: loss = 0.36 (0.023 sec)\n",
      "Step 3100: loss = 0.31 (0.001 sec)\n",
      "Step 3200: loss = 0.28 (0.002 sec)\n",
      "Step 3300: loss = 0.35 (0.164 sec)\n",
      "Step 3400: loss = 0.23 (0.002 sec)\n",
      "Step 3500: loss = 0.30 (0.001 sec)\n",
      "Step 3600: loss = 0.27 (0.001 sec)\n",
      "Step 3700: loss = 0.22 (0.001 sec)\n",
      "Step 3800: loss = 0.42 (0.001 sec)\n",
      "Step 3900: loss = 0.17 (0.001 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 50348  Precision @ 1: 0.9154\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4611  Precision @ 1: 0.9222\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 9187  Precision @ 1: 0.9187\n",
      "Step 4000: loss = 0.25 (0.020 sec)\n",
      "Step 4100: loss = 0.31 (0.001 sec)\n",
      "Step 4200: loss = 0.28 (0.003 sec)\n",
      "Step 4300: loss = 0.31 (0.002 sec)\n",
      "Step 4400: loss = 0.43 (0.172 sec)\n",
      "Step 4500: loss = 0.21 (0.001 sec)\n",
      "Step 4600: loss = 0.27 (0.001 sec)\n",
      "Step 4700: loss = 0.10 (0.002 sec)\n",
      "Step 4800: loss = 0.28 (0.001 sec)\n",
      "Step 4900: loss = 0.21 (0.002 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 50784  Precision @ 1: 0.9233\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4638  Precision @ 1: 0.9276\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 9277  Precision @ 1: 0.9277\n"
     ]
    }
   ],
   "source": [
    "import shutil,os\n",
    "#if os.path.exists(log_dir):\n",
    "#    shutil.rmtree(log_dir)\n",
    "tf.compat.v1.gfile.MakeDirs(log_dir)\n",
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:0 (784, 10)\n",
      "2\n",
      "784\n",
      "10\n",
      "7840\n",
      "Variable_1:0 (10,)\n",
      "1\n",
      "10\n",
      "10\n",
      "7850\n"
     ]
    }
   ],
   "source": [
    "#Count total number of parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.compat.v1.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(variable.name, shape)\n",
    "    print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parameters *= dim\n",
    "    print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
