{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mrityunjay kumar #\n",
    "# CNN Convolution Networks #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import input_data\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs,in_shape,out_shape,layer=None,activation_function=None,dropout=None):\n",
    "    W = weight_variable(in_shape)\n",
    "    b = bias_variable(out_shape)\n",
    "    if layer is \"conv\":\n",
    "        h_conv = activation_function(conv2d(inputs,W)+b)\n",
    "        h_pool = max_pool_2x2(h_conv)\n",
    "        return h_pool\n",
    "    wx_plus_b = tf.compat.v1.matmul(inputs,W)+b\n",
    "    output = activation_function(wx_plus_b)\n",
    "    if dropout is None:\n",
    "        return output\n",
    "    output_dropout = tf.compat.v1.nn.dropout(output,keep_prob)\n",
    "    return output_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(x_v,y_v):\n",
    "    global prediction\n",
    "    ypred = sess.run(prediction,feed_dict={xs:x_v,keep_prob:1})\n",
    "    accurate_counts = tf.compat.v1.equal(tf.compat.v1.argmax(y_v,1),tf.compat.v1.arg_max(ypred,1))\n",
    "    accuracy = tf.compat.v1.reduce_mean(tf.compat.v1.cast(accurate_counts,dtype=tf.compat.v1.float32))\n",
    "    results = sess.run(accuracy,feed_dict={xs:x_v,ys:y_v,keep_prob:1})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.compat.v1.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.compat.v1.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.compat.v1.constant(0.1, shape=shape)\n",
    "    return tf.compat.v1.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    # stride [1,x_movement,y_movement,1]\n",
    "    # # Must have strides[0] = strides[3] = 1\n",
    "    return tf.compat.v1.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    # stride [1,x_movement,y_movement,1]\n",
    "    return tf.compat.v1.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input placeholders\n",
    "xs = tf.compat.v1.placeholder(tf.compat.v1.float32,[None,784])\n",
    "ys = tf.compat.v1.placeholder(tf.compat.v1.float32,[None,10])\n",
    "keep_prob = tf.compat.v1.placeholder(tf.compat.v1.float32)\n",
    "x_image = tf.compat.v1.reshape(xs,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##conv1 layer##\n",
    "h_conv_pool_1 = add_layer(x_image,[5,5,1,32],[32],activation_function=tf.compat.v1.nn.relu,layer='conv')\n",
    "# patch 5x5, in size 1, out size 32\n",
    "# output size 28x28x32  (from conv2d)\n",
    "# output size 14x14x32  (from max_pool_2x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##conv2 layer##\n",
    "h_conv_pool_2 = add_layer(h_conv_pool_1,[5,5,32,64],[64],activation_function=tf.compat.v1.nn.relu,layer='conv')\n",
    "# patch 5x5, in size 32, out size 64\n",
    "# output size 14x14x64 (from conv2d)\n",
    "# output size 7x7x64 (from conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fc layer 1##\n",
    "h_conv_pool_2_flat = tf.compat.v1.reshape(h_conv_pool_2,[-1,7*7*64])\n",
    "fc_1 = add_layer(h_conv_pool_2_flat,[7*7*64,1024],[1024],activation_function=tf.compat.v1.nn.relu,dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fc layer 2##\n",
    "prediction = add_layer(fc_1,[1024,10],[10],activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.compat.v1.reduce_mean(-tf.compat.v1.reduce_sum(ys*tf.compat.v1.log(prediction),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.compat.v1.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0128 16:22:42.273402 4579792320 deprecation.py:323] From <ipython-input-47-376053cd9e53>:4: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1245\n",
      "0.832\n",
      "0.9069\n",
      "0.9285\n",
      "0.9408\n",
      "0.9484\n",
      "0.9548\n",
      "0.9588\n",
      "0.9631\n",
      "0.9632\n",
      "0.9652\n",
      "0.9685\n",
      "0.9687\n",
      "0.9711\n",
      "0.973\n",
      "0.973\n",
      "0.9758\n",
      "0.9761\n",
      "0.9756\n",
      "0.9764\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch_x,label_y = mnist.train.next_batch(200)\n",
    "    sess.run(training,feed_dict={xs:batch_x,ys:label_y,keep_prob:0.5})\n",
    "    if i%50==0:\n",
    "        print(compute_accuracy(mnist.test.images,mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
