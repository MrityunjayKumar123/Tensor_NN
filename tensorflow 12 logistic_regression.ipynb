{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A logistic regression learning algorithm example using TensorFlow library.\n",
    "# This example is using the MNIST database of handwritten digits \n",
    "# (http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "# Author: Aymeric Damien\n",
    "# Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info[0] >= 3:\n",
    "    from urllib.request import urlretrieve\n",
    "else:\n",
    "    # Not Python 3 - today, it is most likely to be Python 2\n",
    "    # But note that this might need an update when Python 4\n",
    "    # might be around one day\n",
    "    from urllib import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'urlretrieve'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a958e231eb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/TensorFlow_Example/TensorFlow-Examples-master/notebooks/2 - Basic Classifiers/input_data.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot)\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mTEST_LABELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m't10k-labels-idx1-ubyte.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0mVALIDATION_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m   \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/TensorFlow_Example/TensorFlow-Examples-master/notebooks/2 - Basic Classifiers/input_data.py\u001b[0m in \u001b[0;36mmaybe_download\u001b[0;34m(filename, work_directory)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOURCE_URL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mstatinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Succesfully downloaded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bytes.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlretrieve'"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "\n",
    "import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '\\u2068/Users\\u2069/\\u2068mrityunjay\\u2069/Desktop\\u2069/\\u2068TensorFlow Examples\\u2069/TensorFlow-Examples-master\\u2069/\\u2068examples\\u2069/2 - Basic Classifiers\\u2069/', '\\u2068/Users\\u2069/\\u2068mrityunjay\\u2069/Desktop\\u2069/\\u2068TensorFlow Examples\\u2069/TensorFlow-Examples-master\\u2069/\\u2068examples\\u2069/2 - Basic Classifiers\\u2069/', '\\u2068Users\\u2069/\\u2068mrityunjay\\u2069/Desktop\\u2069/\\u2068TensorFlow Examples\\u2069/TensorFlow-Examples-master\\u2069/\\u2068examples\\u2069/2 - Basic Classifiers\\u2069/', '/Desktop/TensorFlow/ExamplesTensorFlow-Examples/masternotebooks/2 - Basic Classifiers/', '/Desktop/TensorFlow/ExamplesTensorFlow-Examples/masternotebooks2 - Basic Classifiers/', '/anaconda3/lib/python36.zip', '/anaconda3/lib/python3.6', '/anaconda3/lib/python3.6/lib-dynload', '/anaconda3/lib/python3.6/site-packages', '/anaconda3/lib/python3.6/site-packages/aeosa', '/anaconda3/lib/python3.6/site-packages/IPython/extensions', '/Users/mrityunjay/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "activation = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "# Cross entropy\n",
    "cost = -tf.reduce_sum(y*tf.log(activation)) \n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 29.860479714\n",
      "Epoch: 0002 cost= 22.080549484\n",
      "Epoch: 0003 cost= 21.237104595\n",
      "Epoch: 0004 cost= 20.460196280\n",
      "Epoch: 0005 cost= 20.185128237\n",
      "Epoch: 0006 cost= 19.940297202\n",
      "Epoch: 0007 cost= 19.645111119\n",
      "Epoch: 0008 cost= 19.507218031\n",
      "Epoch: 0009 cost= 19.389794492\n",
      "Epoch: 0010 cost= 19.177005816\n",
      "Epoch: 0011 cost= 19.082493615\n",
      "Epoch: 0012 cost= 19.072873598\n",
      "Epoch: 0013 cost= 18.938005402\n",
      "Epoch: 0014 cost= 18.891806430\n",
      "Epoch: 0015 cost= 18.839480221\n",
      "Epoch: 0016 cost= 18.769349510\n",
      "Epoch: 0017 cost= 18.590865587\n",
      "Epoch: 0018 cost= 18.623413677\n",
      "Epoch: 0019 cost= 18.546149085\n",
      "Epoch: 0020 cost= 18.432274895\n",
      "Epoch: 0021 cost= 18.358189004\n",
      "Epoch: 0022 cost= 18.380014628\n",
      "Epoch: 0023 cost= 18.499993471\n",
      "Epoch: 0024 cost= 18.386477311\n",
      "Epoch: 0025 cost= 18.258080609\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(activation, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
