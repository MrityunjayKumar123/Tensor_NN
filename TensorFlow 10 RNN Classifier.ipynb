{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mrityunjay Kumar #\n",
    "# RNN Classifiers  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mrityunjay kumar #\n",
    "# CNN Convolution Networks #\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "lr = 0.001 #learning rate\n",
    "training_iters = 100000 #number of training iterations\n",
    "batch_size = 128\n",
    "\n",
    "n_inputs = 28   # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28    # time steps (number of time layers)\n",
    "n_hidden_units = 128   # neurons in hidden layer\n",
    "n_classes = 10      # MNIST classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, n_steps, n_inputs])\n",
    "y = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # (28, 128)\n",
    "    'in': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_inputs, n_hidden_units])),\n",
    "    # (128, 10)\n",
    "    'out': tf.compat.v1.Variable(tf.compat.v1.random_normal([n_hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    # (128, )\n",
    "    'in': tf.compat.v1.Variable(tf.compat.v1.constant(0.1, shape=[n_hidden_units, ])),\n",
    "    # (10, )\n",
    "    'out': tf.compat.v1.Variable(tf.compat.v1.constant(0.1, shape=[n_classes, ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(X,weights,biases):\n",
    "    # hidden layer for input to cell\n",
    "    ########################################\n",
    "\n",
    "    # transpose the inputs shape from\n",
    "    # X ==> (128 batch * 28 steps, 28 inputs)\n",
    "    X = tf.compat.v1.reshape(X,[-1,n_steps])\n",
    "    \n",
    "    # into hidden\n",
    "    # X_in = (128 batch * 28 steps, 128 hidden)\n",
    "    X_in = tf.compat.v1.matmul(X,weights['in'])+biases['in']\n",
    "    # X_in ==> (128 batch, 28 steps, 128 hidden)\n",
    "    X_in = tf.compat.v1.reshape(X_in,[-1,n_steps,n_hidden_units])\n",
    "    \n",
    "    # cell\n",
    "    ##########################################\n",
    "\n",
    "    # basic LSTM Cell.\n",
    "    lstm_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(n_hidden_units,forget_bias=1,state_is_tuple=True)\n",
    "    # lstm cell is divided into two parts (c_state, h_state)\n",
    "    _init_state = lstm_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    \n",
    "    # You have 2 options for following step.\n",
    "    # 1: tf.nn.rnn(cell, inputs);\n",
    "    # 2: tf.nn.dynamic_rnn(cell, inputs).\n",
    "    # If use option 1, you have to modified the shape of X_in, go and check out this:\n",
    "    # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    # In here, we go for option 2.\n",
    "    # dynamic_rnn receive Tensor (batch, steps, inputs) or (steps, batch, inputs) as X_in.\n",
    "    # Make sure the time_major is changed accordingly.\n",
    "    # time major is used to put the 1st cell of the tensor shape received by dynamic_rnn as time_steps or not\n",
    "    # here it's [batch_size,steps,inputs]  => so time_major is False.\n",
    "    \n",
    "    outputs, final_state = tf.compat.v1.nn.dynamic_rnn(lstm_cell,initial_state=_init_state,inputs=X_in,time_major=False)\n",
    "    \n",
    "    # hidden layer for output as the final results\n",
    "    #############################################\n",
    "    # results = tf.matmul(final_state[1], weights['out']) + biases['out']\n",
    "\n",
    "    # # or\n",
    "    # unpack to list [(batch, outputs)..] * steps\n",
    "    outputs = tf.compat.v1.unstack(tf.transpose(outputs, [1, 0, 2]))    # states is the last outputs\n",
    "    results = tf.compat.v1.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0129 11:45:43.572850 4445218240 tf_should_use.py:71] ==================================\n",
      "Object was never used (type <class 'tensorflow.python.framework.ops.Operation'>):\n",
      "<tf.Operation 'init' type=NoOp>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()  File \"/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1433, in _run_once\n",
      "    handle = None  # Needed to break cycles when an exception occurs.  File \"/anaconda3/lib/python3.6/asyncio/events.py\", line 157, in _run\n",
      "    self = None  # Needed to break cycles when an exception occurs.  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 776, in _run_callback\n",
      "    self.handle_callback_exception(callback)  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 278, in null_wrapper\n",
      "    _state.contexts = current_state  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 463, in _handle_events\n",
      "    raise  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
      "    raise  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 278, in null_wrapper\n",
      "    _state.contexts = current_state  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 241, in dispatch_shell\n",
      "    self._publish_status(u'idle')  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 258, in do_execute\n",
      "    return reply_content  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2667, in run_cell\n",
      "    return result  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2801, in _run_cell\n",
      "    return result  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2931, in run_ast_nodes\n",
      "    return False  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2983, in run_code\n",
      "    return outflag  File \"<ipython-input-33-7a73be568ca9>\", line 8, in <module>\n",
      "    init = tf.compat.v1.initialize_all_variables()  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "pred = RNN(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "train_op = tf.compat.v1.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "correct_pred = tf.compat.v1.equal(tf.compat.v1.argmax(pred, 1), tf.compat.v1.argmax(y, 1))\n",
    "accuracy = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_pred, tf.compat.v1.float32))\n",
    "\n",
    "init = tf.compat.v1.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375\n",
      "0.125\n",
      "0.0703125\n",
      "0.125\n",
      "0.0390625\n",
      "0.125\n",
      "0.125\n",
      "0.0625\n",
      "0.0703125\n",
      "0.125\n",
      "0.09375\n",
      "0.109375\n",
      "0.09375\n",
      "0.1171875\n",
      "0.140625\n",
      "0.09375\n",
      "0.09375\n",
      "0.0859375\n",
      "0.0703125\n",
      "0.078125\n",
      "0.0546875\n",
      "0.0625\n",
      "0.0625\n",
      "0.078125\n",
      "0.1484375\n",
      "0.125\n",
      "0.0859375\n",
      "0.03125\n",
      "0.09375\n",
      "0.109375\n",
      "0.109375\n",
      "0.1171875\n",
      "0.0859375\n",
      "0.1484375\n",
      "0.15625\n",
      "0.1171875\n",
      "0.109375\n",
      "0.078125\n",
      "0.0859375\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])\n",
    "        sess.run([train_op], feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        })\n",
    "        if step % 20 == 0:\n",
    "            print(sess.run(accuracy, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        }))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
